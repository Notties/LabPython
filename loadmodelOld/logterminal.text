C:\LabPython>C:/Users/aktha/AppData/Local/Programs/Python/Python311/python.exe c:/LabPython/models/newmodels.py
custom_words_list 62055
word_tokenize ['โอเค', 'บ่', 'พวกเรา', 'รัก', 'ภาษา', 'บ้านเกิด']
cleaned_words ['อ้าว   อยาก มีเรื่อง หรอ วะ   ไอ้ หัว เกรียน !']
max_length 619
cleaned_words  อ้าว   อยาก มีเรื่อง หรอ วะ   ไอ้ หัว เกรียน !
encoded_doc  [1965, 27, 1966, 170, 254, 290, 356, 4236]
Shape of padded docs =  (13040, 619)
unique_category  ['negative', 'positive']
category[0:2]  ['negative', 'negative']
encoded_output[0:2] [[1], [1]]
encoded_output.shape  (13040, 1)
encoded_output[0]  [1]
output_one_hot[0]  [1. 0.]
Shape of train_X = (10432, 619) and train_Y = (10432, 2)
Shape of val_X = (2608, 619) and val_Y = (2608, 2)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 619)]        0           []

 input_2 (InputLayer)           [(None, 619)]        0           []

 input_3 (InputLayer)           [(None, 619)]        0           []

 embedding (Embedding)          (None, 619, 100)     1585100     ['input_1[0][0]']

 embedding_1 (Embedding)        (None, 619, 100)     1585100     ['input_2[0][0]']

 embedding_2 (Embedding)        (None, 619, 100)     1585100     ['input_3[0][0]']

 conv1d (Conv1D)                (None, 616, 32)      12832       ['embedding[0][0]']

 conv1d_1 (Conv1D)              (None, 614, 32)      19232       ['embedding_1[0][0]']

 conv1d_2 (Conv1D)              (None, 612, 32)      25632       ['embedding_2[0][0]']

 dropout (Dropout)              (None, 616, 32)      0           ['conv1d[0][0]']

 dropout_1 (Dropout)            (None, 614, 32)      0           ['conv1d_1[0][0]']

 dropout_2 (Dropout)            (None, 612, 32)      0           ['conv1d_2[0][0]']

 max_pooling1d (MaxPooling1D)   (None, 308, 32)      0           ['dropout[0][0]']

 max_pooling1d_1 (MaxPooling1D)  (None, 307, 32)     0           ['dropout_1[0][0]']

 max_pooling1d_2 (MaxPooling1D)  (None, 306, 32)     0           ['dropout_2[0][0]']

 flatten (Flatten)              (None, 9856)         0           ['max_pooling1d[0][0]']

 flatten_1 (Flatten)            (None, 9824)         0           ['max_pooling1d_1[0][0]']

 flatten_2 (Flatten)            (None, 9792)         0           ['max_pooling1d_2[0][0]']

 concatenate (Concatenate)      (None, 29472)        0           ['flatten[0][0]',
                                                                  'flatten_1[0][0]',
                                                                  'flatten_2[0][0]']

 dense (Dense)                  (None, 10)           294730      ['concatenate[0][0]']

 dense_1 (Dense)                (None, 2)            22          ['dense[0][0]']

==================================================================================================
Total params: 5,107,748
Trainable params: 352,448
Non-trainable params: 4,755,300
__________________________________________________________________________________________________
None
Epoch 1/100
326/326 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.6645  
Epoch 1: val_loss improved from inf to 0.56788, saving model to model2.h5
326/326 [==============================] - 30s 91ms/step - loss: 0.6105 - accuracy: 0.6645 - val_loss: 0.5679 - val_accuracy: 0.7048 - lr: 1.0000e-04
Epoch 2/100
326/326 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.7352 
Epoch 2: val_loss improved from 0.56788 to 0.51886, saving model to model2.h5
326/326 [==============================] - 32s 99ms/step - loss: 0.5270 - accuracy: 0.7352 - val_loss: 0.5189 - val_accuracy: 0.7458 - lr: 1.0000e-04
Epoch 3/100
326/326 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.7670 
Epoch 3: val_loss improved from 0.51886 to 0.50187, saving model to model2.h5
326/326 [==============================] - 30s 92ms/step - loss: 0.4837 - accuracy: 0.7670 - val_loss: 0.5019 - val_accuracy: 0.7638 - lr: 1.0000e-04
Epoch 4/100
326/326 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.7870 
Epoch 4: val_loss improved from 0.50187 to 0.49504, saving model to model2.h5
326/326 [==============================] - 31s 94ms/step - loss: 0.4621 - accuracy: 0.7870 - val_loss: 0.4950 - val_accuracy: 0.7515 - lr: 1.0000e-04
Epoch 5/100
326/326 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.7921 
Epoch 5: val_loss improved from 0.49504 to 0.48734, saving model to model2.h5
326/326 [==============================] - 29s 90ms/step - loss: 0.4476 - accuracy: 0.7921 - val_loss: 0.4873 - val_accuracy: 0.7765 - lr: 1.0000e-04
Epoch 6/100
326/326 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.8051 
Epoch 6: val_loss improved from 0.48734 to 0.48471, saving model to model2.h5
326/326 [==============================] - 30s 91ms/step - loss: 0.4317 - accuracy: 0.8051 - val_loss: 0.4847 - val_accuracy: 0.7757 - lr: 1.0000e-04
Epoch 7/100
326/326 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8078 
Epoch 7: val_loss improved from 0.48471 to 0.48080, saving model to model2.h5
326/326 [==============================] - 30s 91ms/step - loss: 0.4173 - accuracy: 0.8078 - val_loss: 0.4808 - val_accuracy: 0.7776 - lr: 1.0000e-04
Epoch 8/100
326/326 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8155 
Epoch 8: val_loss improved from 0.48080 to 0.47703, saving model to model2.h5
326/326 [==============================] - 30s 91ms/step - loss: 0.4074 - accuracy: 0.8155 - val_loss: 0.4770 - val_accuracy: 0.7807 - lr: 1.0000e-04
Epoch 9/100
326/326 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.8213 
Epoch 9: val_loss improved from 0.47703 to 0.47667, saving model to model2.h5
326/326 [==============================] - 30s 91ms/step - loss: 0.3950 - accuracy: 0.8213 - val_loss: 0.4767 - val_accuracy: 0.7803 - lr: 1.0000e-04
Epoch 10/100
326/326 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8257 
Epoch 10: val_loss improved from 0.47667 to 0.47432, saving model to model2.h5
326/326 [==============================] - 30s 92ms/step - loss: 0.3828 - accuracy: 0.8257 - val_loss: 0.4743 - val_accuracy: 0.7803 - lr: 1.0000e-04
Epoch 11/100
326/326 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.8318 
Epoch 11: val_loss did not improve from 0.47432
326/326 [==============================] - 30s 92ms/step - loss: 0.3688 - accuracy: 0.8318 - val_loss: 0.4764 - val_accuracy: 0.7776 - lr: 1.0000e-04
Epoch 12/100
326/326 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.8348 
Epoch 12: val_loss did not improve from 0.47432
326/326 [==============================] - 30s 93ms/step - loss: 0.3618 - accuracy: 0.8348 - val_loss: 0.4749 - val_accuracy: 0.7745 - lr: 1.0000e-04
Epoch 13/100
326/326 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8467 
Epoch 13: val_loss did not improve from 0.47432

Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
326/326 [==============================] - 30s 92ms/step - loss: 0.3495 - accuracy: 0.8467 - val_loss: 0.4770 - val_accuracy: 0.7765 - lr: 1.0000e-04
Epoch 14/100
326/326 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.8513 
Epoch 14: val_loss improved from 0.47432 to 0.47209, saving model to model2.h5
326/326 [==============================] - 30s 93ms/step - loss: 0.3373 - accuracy: 0.8513 - val_loss: 0.4721 - val_accuracy: 0.7818 - lr: 1.0000e-05
Epoch 15/100
326/326 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8488 
Epoch 15: val_loss did not improve from 0.47209
326/326 [==============================] - 29s 90ms/step - loss: 0.3366 - accuracy: 0.8488 - val_loss: 0.4730 - val_accuracy: 0.7776 - lr: 1.0000e-05
Epoch 16/100
326/326 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8502 
Epoch 16: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3343 - accuracy: 0.8502 - val_loss: 0.4743 - val_accuracy: 0.7772 - lr: 1.0000e-05
Epoch 17/100
326/326 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.8500 
Epoch 17: val_loss did not improve from 0.47209

Epoch 17: ReduceLROnPlateau reducing learning rate to 1e-06.
326/326 [==============================] - 30s 92ms/step - loss: 0.3318 - accuracy: 0.8500 - val_loss: 0.4742 - val_accuracy: 0.7791 - lr: 1.0000e-05
Epoch 18/100
326/326 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.8540 
Epoch 18: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3316 - accuracy: 0.8540 - val_loss: 0.4739 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 19/100
326/326 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8484 
Epoch 19: val_loss did not improve from 0.47209
326/326 [==============================] - 29s 90ms/step - loss: 0.3320 - accuracy: 0.8484 - val_loss: 0.4738 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 20/100
326/326 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8545 
Epoch 20: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3298 - accuracy: 0.8545 - val_loss: 0.4737 - val_accuracy: 0.7814 - lr: 1.0000e-06
Epoch 21/100
326/326 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8522 
Epoch 21: val_loss did not improve from 0.47209
326/326 [==============================] - 29s 90ms/step - loss: 0.3352 - accuracy: 0.8522 - val_loss: 0.4736 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 22/100
326/326 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.8497 
Epoch 22: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 94ms/step - loss: 0.3318 - accuracy: 0.8497 - val_loss: 0.4736 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 23/100
326/326 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8522 
Epoch 23: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 91ms/step - loss: 0.3302 - accuracy: 0.8522 - val_loss: 0.4736 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 24/100
326/326 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8529 
Epoch 24: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3279 - accuracy: 0.8529 - val_loss: 0.4736 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 25/100
326/326 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8561 
Epoch 25: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3300 - accuracy: 0.8561 - val_loss: 0.4736 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 26/100
326/326 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.8512 
Epoch 26: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3325 - accuracy: 0.8512 - val_loss: 0.4737 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 27/100
326/326 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8538 
Epoch 27: val_loss did not improve from 0.47209
326/326 [==============================] - 29s 90ms/step - loss: 0.3287 - accuracy: 0.8538 - val_loss: 0.4737 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 28/100
326/326 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8508 
Epoch 28: val_loss did not improve from 0.47209
326/326 [==============================] - 29s 90ms/step - loss: 0.3322 - accuracy: 0.8508 - val_loss: 0.4737 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 29/100
326/326 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8516 
Epoch 29: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3308 - accuracy: 0.8516 - val_loss: 0.4738 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 30/100
326/326 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8512 
Epoch 30: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 96ms/step - loss: 0.3305 - accuracy: 0.8512 - val_loss: 0.4738 - val_accuracy: 0.7814 - lr: 1.0000e-06
Epoch 31/100
326/326 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.8507 
Epoch 31: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 94ms/step - loss: 0.3327 - accuracy: 0.8507 - val_loss: 0.4739 - val_accuracy: 0.7791 - lr: 1.0000e-06
Epoch 32/100
326/326 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.8509 
Epoch 32: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 94ms/step - loss: 0.3295 - accuracy: 0.8509 - val_loss: 0.4739 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 33/100
326/326 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8543 
Epoch 33: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3305 - accuracy: 0.8543 - val_loss: 0.4739 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 34/100
326/326 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.8522 
Epoch 34: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 94ms/step - loss: 0.3315 - accuracy: 0.8522 - val_loss: 0.4738 - val_accuracy: 0.7814 - lr: 1.0000e-06
Epoch 35/100
326/326 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8538 
Epoch 35: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 95ms/step - loss: 0.3312 - accuracy: 0.8538 - val_loss: 0.4738 - val_accuracy: 0.7814 - lr: 1.0000e-06
Epoch 36/100
326/326 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8505 
Epoch 36: val_loss did not improve from 0.47209
326/326 [==============================] - 37s 113ms/step - loss: 0.3308 - accuracy: 0.8505 - val_loss: 0.4738 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 37/100
326/326 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.8546 
Epoch 37: val_loss did not improve from 0.47209
326/326 [==============================] - 32s 99ms/step - loss: 0.3303 - accuracy: 0.8546 - val_loss: 0.4737 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 38/100
326/326 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8492 
Epoch 38: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 95ms/step - loss: 0.3247 - accuracy: 0.8571 - val_loss: 0.4739 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 48/100
326/326 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.8563
Epoch 48: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 93ms/step - loss: 0.3267 - accuracy: 0.8563 - val_loss: 0.4739 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 49/100
326/326 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.8541
Epoch 49: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3271 - accuracy: 0.8541 - val_loss: 0.4739 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 50/100
326/326 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 0.8534
Epoch 50: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 93ms/step - loss: 0.3260 - accuracy: 0.8534 - val_loss: 0.4740 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 51/100
326/326 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.8524
Epoch 51: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 93ms/step - loss: 0.3274 - accuracy: 0.8524 - val_loss: 0.4740 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 52/100
326/326 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8547
Epoch 52: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 96ms/step - loss: 0.3270 - accuracy: 0.8547 - val_loss: 0.4739 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 53/100
326/326 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8530 
Epoch 53: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 95ms/step - loss: 0.3278 - accuracy: 0.8530 - val_loss: 0.4740 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 54/100
326/326 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.8538 
Epoch 54: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3264 - accuracy: 0.8538 - val_loss: 0.4739 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 55/100
326/326 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.8510 
Epoch 55: val_loss did not improve from 0.47209
326/326 [==============================] - 31s 94ms/step - loss: 0.3273 - accuracy: 0.8510 - val_loss: 0.4740 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 56/100
326/326 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.8502 
Epoch 56: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 106ms/step - loss: 0.3268 - accuracy: 0.8502 - val_loss: 0.4739 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 57/100
326/326 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8508 
Epoch 57: val_loss did not improve from 0.47209
326/326 [==============================] - 39s 119ms/step - loss: 0.3272 - accuracy: 0.8508 - val_loss: 0.4739 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 58/100
326/326 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8564 
Epoch 58: val_loss did not improve from 0.47209
326/326 [==============================] - 40s 121ms/step - loss: 0.3232 - accuracy: 0.8564 - val_loss: 0.4740 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 59/100
326/326 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.8516 
Epoch 59: val_loss did not improve from 0.47209
326/326 [==============================] - 33s 101ms/step - loss: 0.3262 - accuracy: 0.8516 - val_loss: 0.4741 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 60/100
326/326 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.8560 
Epoch 60: val_loss did not improve from 0.47209
326/326 [==============================] - 35s 107ms/step - loss: 0.3264 - accuracy: 0.8560 - val_loss: 0.4741 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 61/100
326/326 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8523 
Epoch 61: val_loss did not improve from 0.47209
326/326 [==============================] - 41s 127ms/step - loss: 0.3298 - accuracy: 0.8523 - val_loss: 0.4742 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 62/100
326/326 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.8551 
Epoch 62: val_loss did not improve from 0.47209
326/326 [==============================] - 39s 120ms/step - loss: 0.3274 - accuracy: 0.8551 - val_loss: 0.4742 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 63/100
326/326 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8521  
Epoch 63: val_loss did not improve from 0.47209
326/326 [==============================] - 41s 126ms/step - loss: 0.3312 - accuracy: 0.8521 - val_loss: 0.4742 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 64/100
326/326 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.8533 
Epoch 64: val_loss did not improve from 0.47209
326/326 [==============================] - 36s 111ms/step - loss: 0.3294 - accuracy: 0.8533 - val_loss: 0.4743 - val_accuracy: 0.7795 - lr: 1.0000e-06
Epoch 65/100
326/326 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8523 
Epoch 65: val_loss did not improve from 0.47209
326/326 [==============================] - 32s 98ms/step - loss: 0.3278 - accuracy: 0.8523 - val_loss: 0.4743 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 66/100
326/326 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8527 
Epoch 66: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 91ms/step - loss: 0.3320 - accuracy: 0.8527 - val_loss: 0.4742 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 67/100
326/326 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8531 
Epoch 67: val_loss did not improve from 0.47209
326/326 [==============================] - 29s 90ms/step - loss: 0.3240 - accuracy: 0.8531 - val_loss: 0.4742 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 68/100
326/326 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8570 
Epoch 68: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3240 - accuracy: 0.8570 - val_loss: 0.4742 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 69/100
326/326 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.8530 
Epoch 69: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 91ms/step - loss: 0.3273 - accuracy: 0.8530 - val_loss: 0.4743 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 70/100
326/326 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8555 
Epoch 70: val_loss did not improve from 0.47209
326/326 [==============================] - 30s 92ms/step - loss: 0.3279 - accuracy: 0.8555 - val_loss: 0.4743 - val_accuracy: 0.7795 - lr: 1.0000e-06
Epoch 71/100
326/326 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8549 
Epoch 71: val_loss did not improve from 0.47209
326/326 [==============================] - 39s 119ms/step - loss: 0.3250 - accuracy: 0.8549 - val_loss: 0.4744 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 72/100
326/326 [==============================] - ETA: 0s - loss: 0.3284 - accuracy: 0.8537 
Epoch 72: val_loss did not improve from 0.47209
326/326 [==============================] - 39s 119ms/step - loss: 0.3284 - accuracy: 0.8537 - val_loss: 0.4743 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 73/100
326/326 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8552 
Epoch 73: val_loss did not improve from 0.47209
326/326 [==============================] - 39s 119ms/step - loss: 0.3251 - accuracy: 0.8552 - val_loss: 0.4744 - val_accuracy: 0.7814 - lr: 1.0000e-06
Epoch 74/100
326/326 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.8492 
Epoch 74: val_loss did not improve from 0.47209
326/326 [==============================] - 39s 119ms/step - loss: 0.3294 - accuracy: 0.8492 - val_loss: 0.4744 - val_accuracy: 0.7811 - lr: 1.0000e-06
Epoch 75/100
326/326 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8543 
Epoch 75: val_loss did not improve from 0.47209
326/326 [==============================] - 39s 118ms/step - loss: 0.3270 - accuracy: 0.8543 - val_loss: 0.4745 - val_accuracy: 0.7807 - lr: 1.0000e-06
Epoch 76/100
326/326 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.8529 
Epoch 76: val_loss did not improve from 0.47209
326/326 [==============================] - 38s 116ms/step - loss: 0.3285 - accuracy: 0.8529 - val_loss: 0.4745 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 77/100
326/326 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8540 
Epoch 77: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3237 - accuracy: 0.8540 - val_loss: 0.4745 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 78/100
326/326 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.8523 
Epoch 78: val_loss did not improve from 0.47209
326/326 [==============================] - 33s 102ms/step - loss: 0.3231 - accuracy: 0.8523 - val_loss: 0.4745 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 79/100
326/326 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.8580 
Epoch 79: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3215 - accuracy: 0.8580 - val_loss: 0.4745 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 80/100
326/326 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8544 
Epoch 80: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3251 - accuracy: 0.8544 - val_loss: 0.4746 - val_accuracy: 0.7788 - lr: 1.0000e-06
Epoch 81/100
326/326 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8569 
Epoch 81: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 105ms/step - loss: 0.3278 - accuracy: 0.8569 - val_loss: 0.4746 - val_accuracy: 0.7795 - lr: 1.0000e-06
Epoch 82/100
326/326 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.8532 
Epoch 82: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3294 - accuracy: 0.8532 - val_loss: 0.4746 - val_accuracy: 0.7788 - lr: 1.0000e-06
Epoch 83/100
326/326 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.8579 
Epoch 83: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 105ms/step - loss: 0.3215 - accuracy: 0.8579 - val_loss: 0.4746 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 84/100
326/326 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.8575 
Epoch 84: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 105ms/step - loss: 0.3228 - accuracy: 0.8575 - val_loss: 0.4747 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 85/100
326/326 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8546 
Epoch 85: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 103ms/step - loss: 0.3232 - accuracy: 0.8546 - val_loss: 0.4747 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 86/100
326/326 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8519 
Epoch 86: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3257 - accuracy: 0.8519 - val_loss: 0.4746 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 87/100
326/326 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8529 
Epoch 87: val_loss did not improve from 0.47209
326/326 [==============================] - 33s 102ms/step - loss: 0.3275 - accuracy: 0.8529 - val_loss: 0.4746 - val_accuracy: 0.7803 - lr: 1.0000e-06
Epoch 88/100
326/326 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.8562 
Epoch 88: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3238 - accuracy: 0.8562 - val_loss: 0.4746 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 89/100
326/326 [==============================] - ETA: 0s - loss: 0.3220 - accuracy: 0.8582 
Epoch 89: val_loss did not improve from 0.47209
326/326 [==============================] - 35s 107ms/step - loss: 0.3220 - accuracy: 0.8582 - val_loss: 0.4746 - val_accuracy: 0.7799 - lr: 1.0000e-06
Epoch 90/100
326/326 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.8532 
Epoch 90: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 105ms/step - loss: 0.3228 - accuracy: 0.8532 - val_loss: 0.4746 - val_accuracy: 0.7795 - lr: 1.0000e-06
Epoch 91/100
326/326 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8554 
Epoch 100: val_loss did not improve from 0.47209
326/326 [==============================] - 34s 104ms/step - loss: 0.3251 - accuracy: 0.8511 - val_loss: 0.4747 - val_accuracy: 0.7811 - lr: 1.0000e-06
Validate loss: 0.47209012508392334
Validate accuracy: 0.7818251252174377
82/82 [==============================] - 2s 21ms/step
predicted_classes (2608,)
[0. 1.]
1
              precision    recall  f1-score   support

    negative     0.7987    0.8494    0.8232      1560
    positive     0.7524    0.6813    0.7151      1048

    accuracy                         0.7818      2608
   macro avg     0.7755    0.7653    0.7692      2608
weighted avg     0.7801    0.7818    0.7798      2608


C:\LabPython>                 